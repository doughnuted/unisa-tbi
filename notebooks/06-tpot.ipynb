{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TPOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "01-data-labelling.ipynb\n02-data-cleaning.ipynb\n  Dropping AgeinYears, CTDone, CTForm1, CTSed, CTSedAge, CTSedAgitate, CTSedOth, CTSedRqst, Certification, DeathTBI, EDCT, EDDisposition, EmplType, Finding1, Finding10, Finding11, Finding12, Finding13, Finding14, Finding2, Finding20, Finding21, Finding22, Finding23, Finding3, Finding4, Finding5, Finding6, Finding7, Finding8, Finding9, GCSGroup, High_impact_InjSev, HospHead, HospHeadPosCT, IndAMS, IndAge, IndAmnesia, IndClinSFx, IndHA, IndHema, IndLOC, IndMech, IndNeuroD, IndOth, IndRqstMD, IndRqstParent, IndRqstTrauma, IndSeiz, IndVomit, IndXraySFx, Intub24Head, Neurosurgery, Observed, PosCT\n  PosIntFinal - Dropping 20 rows where PosIntFinal is NaN\n  Gender - Dropping 3 rows where Gender is NaN\n  Filling missing GCSEye, GCSVerbal, GCSMotor when GCSTotal is 15\n  GCSTotal - Dropping as it is now redundant\n  AgeInMonths - Renaming to Age\n  Renaming InjuryMech to Injury_Mechanism\n  Renaming ActNorm to Acting_Normal\n03-data-imputation.ipynb\n  The imputed dataset is now available in a dataframe named \"pecarn_imputed\"\n04-feature-engineering.ipynb\nSTART: 06-TPOT.ipynb\n"
    }
   ],
   "source": [
    "%run notebooks/04-feature-engineering.ipynb\n",
    "\n",
    "print(\"START: 06-TPOT.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arrange Data\n",
    "Need to convert the dataframes to numpy arrays so that TPOT can work with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pecarn_imputed.copy()\n",
    "\n",
    "label = features['PosIntFinal']\n",
    "label = features['PosIntFinal'].cat.codes\n",
    "label = label.to_numpy(dtype=np.int32)\n",
    "\n",
    "attributes = features.drop(columns='PosIntFinal')\n",
    "for col in attributes:\n",
    "    if attributes[col].dtype == 'category':\n",
    "        attributes[col] = attributes[col].cat.codes\n",
    "attributes = attributes.to_numpy(dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#features = pecarn_cleaned.copy()\n",
    "\n",
    "#y = features['PosIntFinal']\n",
    "#X = features.drop(columns='PosIntFinal')\n",
    "y = label\n",
    "X = attributes\n",
    "\n",
    "# create training and test splits - this will act as a hold out set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75, test_size=0.25, stratify=y)\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure TPOT\n",
    "Initial attempts to use the TPOT Light template were taking a long time too complete.\n",
    "\n",
    "We create a tpot_config that is based on the TPOT Light template, and removing in particular preprocessors that we aren't interested in.\n",
    "\n",
    "See https://github.com/EpistasisLab/tpot/blob/master/tpot/config/classifier_light.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/EpistasisLab/tpot/blob/master/tpot/config/classifier_light.py\n",
    "# https://github.com/EpistasisLab/tpot/blob/master/tpot/config/classifier.py\n",
    "\n",
    "# specify the pipelines that TPOT will optmize - selected from the two default classifiers\n",
    "tpot_config = {\n",
    "\n",
    "    # # Classifiers\n",
    "    # 'sklearn.naive_bayes.GaussianNB': {\n",
    "    # },\n",
    "\n",
    "    # 'sklearn.naive_bayes.BernoulliNB': {\n",
    "    #     'alpha': [1e-3, 1e-2, 1e-1, 1., 10., 100.],\n",
    "    #     'fit_prior': [True, False]\n",
    "    # },\n",
    "\n",
    "    # 'sklearn.naive_bayes.MultinomialNB': {\n",
    "    #     'alpha': [1e-3, 1e-2, 1e-1, 1., 10., 100.],\n",
    "    #     'fit_prior': [True, False]\n",
    "    # },\n",
    "\n",
    "    'sklearn.tree.DecisionTreeClassifier': {\n",
    "        'criterion': [\"gini\", \"entropy\"],\n",
    "        'max_depth': range(1, 11),\n",
    "        'min_samples_split': range(2, 21),\n",
    "        'min_samples_leaf': range(1, 21)\n",
    "    },\n",
    "\n",
    "    # 'sklearn.ensemble.ExtraTreesClassifier': {\n",
    "    #     'n_estimators': [100],\n",
    "    #     'criterion': [\"gini\", \"entropy\"],\n",
    "    #     'max_features': np.arange(0.05, 1.01, 0.05),\n",
    "    #     'min_samples_split': range(2, 21),\n",
    "    #     'min_samples_leaf': range(1, 21),\n",
    "    #     'bootstrap': [True, False]\n",
    "    # },\n",
    "\n",
    "    # 'xgboost.XGBClassifier': {\n",
    "    #     'n_estimators': [100],\n",
    "    #     'max_depth': range(1, 11),\n",
    "    #     'learning_rate': [1e-3, 1e-2, 1e-1, 0.5, 1.],\n",
    "    #     'subsample': np.arange(0.05, 1.01, 0.05),\n",
    "    #     'min_child_weight': range(1, 21),\n",
    "    #     'nthread': [1]\n",
    "    # },\n",
    "\n",
    "    # 'sklearn.neighbors.KNeighborsClassifier': {\n",
    "    #     'n_neighbors': range(1, 101),\n",
    "    #     'weights': [\"uniform\", \"distance\"],\n",
    "    #     'p': [1, 2]\n",
    "    # },\n",
    "\n",
    "\n",
    "    # 'sklearn.linear_model.LogisticRegression': {\n",
    "    #     'penalty': [\"l1\", \"l2\"],\n",
    "    #     'C': [1e-4, 1e-3, 1e-2, 1e-1, 0.5, 1., 5., 10., 15., 20., 25.],\n",
    "    #     'dual': [True, False]\n",
    "    # },\n",
    "\n",
    "    # Preprocesssors\n",
    "    # 'sklearn.cluster.FeatureAgglomeration': {\n",
    "    #     'linkage': ['ward', 'complete', 'average'],\n",
    "    #     'affinity': ['euclidean', 'l1', 'l2', 'manhattan', 'cosine']\n",
    "    # },\n",
    "\n",
    "    # 'sklearn.decomposition.PCA': {\n",
    "    #     'svd_solver': ['randomized'],\n",
    "    #     'iterated_power': range(1, 11)\n",
    "    # },\n",
    "\n",
    "    # 'sklearn.kernel_approximation.RBFSampler': {\n",
    "    #     'gamma': np.arange(0.0, 1.01, 0.05)\n",
    "    # },\n",
    "\n",
    "    # 'sklearn.preprocessing.RobustScaler': {\n",
    "    # },\n",
    "\n",
    "    # 'sklearn.preprocessing.StandardScaler': {\n",
    "    # },\n",
    "\n",
    "    'sklearn.preprocessing.OneHotEncoder': {\n",
    "        'drop': 'first'\n",
    "    }\n",
    "\n",
    "    # 'tpot.builtins.OneHotEncoder': {\n",
    "    #     'minimum_fraction': [0.05, 0.1, 0.15, 0.2, 0.25],\n",
    "    #     'sparse': [False],\n",
    "    #     'threshold': [10]\n",
    "    # },\n",
    "\n",
    "    # Selectors\n",
    "    # 'sklearn.feature_selection.SelectFwe': {\n",
    "    #     'alpha': np.arange(0, 0.05, 0.001),\n",
    "    #     'score_func': {\n",
    "    #         'sklearn.feature_selection.f_classif': None\n",
    "    #     }\n",
    "    # },\n",
    "\n",
    "    # 'sklearn.feature_selection.VarianceThreshold': {\n",
    "    #     'threshold': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.2]\n",
    "    # }\n",
    "\n",
    "    # 'sklearn.feature_selection.SelectFromModel': {\n",
    "    #     'threshold': np.arange(0, 1.01, 0.05),\n",
    "    #     'estimator': {\n",
    "    #         'sklearn.ensemble.ExtraTreesClassifier': {\n",
    "    #             'n_estimators': [100],\n",
    "    #             'criterion': ['gini', 'entropy'],\n",
    "    #             'max_features': np.arange(0.05, 1.01, 0.05)\n",
    "    #         }\n",
    "    #     }\n",
    "    # }\n",
    "\n",
    "}\n",
    "\n",
    "from tpot import TPOTClassifier\n",
    "\n",
    "# create TPOT optimizer\n",
    "clf_opt = TPOTClassifier(\n",
    "                        #config_dict='TPOT light',\n",
    "                        scoring='f1',\n",
    "                        \n",
    "                        #generations=10,\n",
    "                        #population_size=50, \n",
    "                        #memory='auto',\n",
    "                        n_jobs=-1,\n",
    "                        #early_stop=3,\n",
    "                        verbosity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call TPOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Optimization Progress:  18%|█▊        | 100/550 [00:19<42:39,  5.69s/pipeline]Generation 1 - Current best internal CV score: 0.48523269244901934\nOptimization Progress:  27%|██▋       | 150/550 [00:30<18:53,  2.83s/pipeline]Generation 2 - Current best internal CV score: 0.4885018258712249\nOptimization Progress:  36%|███▋      | 200/550 [00:38<10:06,  1.73s/pipeline]Generation 3 - Current best internal CV score: 0.48870181446838734\nOptimization Progress:  45%|████▌     | 250/550 [00:50<10:39,  2.13s/pipeline]Generation 4 - Current best internal CV score: 0.4921316110789795\nOptimization Progress:  55%|█████▍    | 300/550 [01:02<06:19,  1.52s/pipeline]Generation 5 - Current best internal CV score: 0.49740000281522556\nOptimization Progress:  64%|██████▍   | 352/550 [01:15<03:14,  1.02pipeline/s]Generation 6 - Current best internal CV score: 0.49740000281522556\nOptimization Progress:  73%|███████▎  | 400/550 [01:30<08:46,  3.51s/pipeline]Generation 7 - Current best internal CV score: 0.49740000281522556\nOptimization Progress:  82%|████████▏ | 450/550 [01:45<03:15,  1.95s/pipeline]Generation 8 - Current best internal CV score: 0.4998521465697728\nOptimization Progress:  91%|█████████ | 500/550 [02:02<01:02,  1.24s/pipeline]Generation 9 - Current best internal CV score: 0.4998521465697728\n\nThe optimized pipeline was not improved after evaluating 3 more generations. Will end the optimization process.\n\nTPOT closed prematurely. Will use the current best pipeline.\n\nBest pipeline: DecisionTreeClassifier(CombineDFs(DecisionTreeClassifier(input_matrix, criterion=gini, max_depth=4, min_samples_leaf=20, min_samples_split=16), input_matrix), criterion=gini, max_depth=1, min_samples_leaf=1, min_samples_split=17)\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "TPOTClassifier(config_dict={'sklearn.preprocessing.OneHotEncoder': {'drop': 'first'},\n                            'sklearn.tree.DecisionTreeClassifier': {'criterion': ['gini',\n                                                                                  'entropy'],\n                                                                    'max_depth': range(1, 11),\n                                                                    'min_samples_leaf': range(1, 21),\n                                                                    'min_samples_split': range(2, 21)}},\n               crossover_rate=0.1, cv=5, disable_update_check=False,\n               early_stop=3, generations=10, max_eval_time_mins=5,\n               max_time_mins=None, memory=None, mutation_rate=0.9, n_jobs=-1,\n               offspring_size=None, periodic_checkpoint_folder=None,\n               population_size=50, random_state=None, scoring='f1',\n               subsample=1.0, template=None, use_dask=False, verbosity=2,\n               warm_start=False)"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "clf_opt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.4359861591695502\n"
    }
   ],
   "source": [
    "print(clf_opt.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Pipeline(memory=None,\n         steps=[('featureunion',\n                 FeatureUnion(n_jobs=None,\n                              transformer_list=[('stackingestimator',\n                                                 StackingEstimator(estimator=DecisionTreeClassifier(ccp_alpha=0.0,\n                                                                                                    class_weight=None,\n                                                                                                    criterion='gini',\n                                                                                                    max_depth=4,\n                                                                                                    max_features=None,\n                                                                                                    max_leaf_nodes=None,\n                                                                                                    min_impurity_decrease=0.0,\n                                                                                                    min_impurity_split=None,\n                                                                                                    min_samples_leaf=20,\n                                                                                                    min_samples_split=16,\n                                                                                                    m...\n                              transformer_weights=None, verbose=False)),\n                ('decisiontreeclassifier',\n                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,\n                                        criterion='gini', max_depth=1,\n                                        max_features=None, max_leaf_nodes=None,\n                                        min_impurity_decrease=0.0,\n                                        min_impurity_split=None,\n                                        min_samples_leaf=1,\n                                        min_samples_split=17,\n                                        min_weight_fraction_leaf=0.0,\n                                        presort='deprecated', random_state=None,\n                                        splitter='best'))],\n         verbose=False)"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "clf_opt.fitted_pipeline_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_opt.export('pipelines/tpot_tbi_pipeline.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}